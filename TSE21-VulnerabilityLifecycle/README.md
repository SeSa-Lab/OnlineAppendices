# The Secret Life of Software Vulnerabilities: A Large-Scale Empirical Study

This `README.md` file contains (1) a description of the datasets employed and (2) the steps needed to rerun the extraction and analysis scripts.

This package is made of two main directories:

- `data/`, containing all the datasets employed.
- `scripts/`, containing the Python scripts to extract and analyze the data.

## Datasets

Here we reported a brief description of each dataset in `data/`:

- `nvd_raw.json` contains the the raw export of NVD (taken [here](https://www.cve-search.org/dataset/)) in date **1st November 2020**. This dataset was used as basis for the entire study.
- `cves.json` contains the pretty printed CVE data extracted from `nvd_raw.json` (so, all irrelevant data were removed). Schema:
  - `cve` - CVE ID
  - `cwe` - Related CWE 
  - `fixes` - List of fixing commits
    - `repo` - GitHub repository URL
    - `hash` - Fixing commit hash
- `repos_enriched` contains details of all 1,163 repositories considered in this study. Schema:
  - `repo` - GitHub repository URL
  - `creation_date` - First commit date (YYYY-MM-DD HH:MM:SS±HH:MM)
  - `cves` - CVEs affecting the repository
    - `cve` - CVE ID
    - `cwe` - Related CWE
    - `commits_before_last_fix` - Number of commits between this commit and the fixing commit with the greatest date
    - `fixes` - List of fixing commits
      - `hash` - Fixing commit hash
      - `message` - Fixing commit message
      - `date` - Fixing commit author date (YYYY-MM-DD HH:MM:SS±HH:MM)
      - `author` - Fixing commit author email
      - `files` - Modified files (**excluding non-source and test files**)
      - `added_lines` - Total number of added lines to `files`
      - `removed_lines` - Total number of removed lines from `files`
      - `inducings` - List of detailed inducing commits
        - `hash` - Inducing commit Hash
        - `message` - Inducing commit message (cleaned from newlines and other special characters)
        - `date` - Inducing commit author date (YYYY-MM-DD HH:MM:SS±HH:MM)
        - `author` - Inducing commit author email
        - `author_workload` - Author percentile of the distribution of workloads (i.e., number of commits) among all developers in the same month of `date`
        - `author_tenure` - Author percentile of the distribution of tenures (i.e., number of elapsed months) among all developers up to `date`
        - `nearest_release_name` - Name of the tag (mostly the version number) of the first release after the inducing commit
        - `nearest_release_date` - Date of the first release after the inducing commit (YYYY-MM-DD HH:MM:SS±HH:MM)
        - `added_lines` - Total number of added lines to **all** changed files
        - `removed_lines` - Total number of removed lines to **all** changed files
        - `commits_before_fix` - Number of commits between this commit and the related fixing commit
        - `file` - Full name of the modified file (**excluding test files**)
        - `commits_since_creation` - Number of commits between the original creation of `file` (**considering the renamings as well**) and the inducing commit (inclusive)
- `projects_info` contains the main information of the considered projects. Schema:
  - `project` - Project name
  - `url` - GitHub repository URL
  - `commits` - Number of non-merge commits made on the main branch (in date 1st November 2020)
  - `contributors` - Number of authors that contributed on the main branch (in date 1st November 2020)
  - `cves` - Number of CVEs
- `szz_validation` contains the outcome of the manual validation of SZZ. Schema:
  - `cve` - CVE ID
  - `inducing_hash` - Randomly-selected Inducing Commit hash
  - `fix_hash` - Related Fixing Commit hash
  - `inspector_1` - Opinion of the first inspector (1 means "correct")
  - `inspector_2` - Opinion of the second inspector (1 means "correct")
  - `inspector_3` - Opinion of the third additional inspector (1 means "correct")
  - `final_outcome`- Modified outcome after the discussion of `inspector_1` and `inspector_2`
- `top_10_cwe` contains the top 10 CWE (Table 1 in the paper).
- `rq1_input.csv` contains the input for `rq1.py`, i.e., inducing commits and how they affected the project files
- `rq2_input.csv` contains the input for `rq2.py`, i.e., inducing commits details for obtaining the commit goal and developer status
- `rq3_input.csv` contains the input for `rq3.py`, i.e., CVEs with their turning point and last fix hash for the survival analysis
- `rq4_input.csv` contains the input for `rq4.py`, i.e., fixing commits details for their categorization
- `rq2_discarded.csv` contains the discarded inducing commits due to their unsuitability for `rq2.py`
- `rq3_discarded.csv` contains the discarded CVEs due to their unsuitability for `rq3.py`
- `removal_methods.csv` (`;`-separated) contains the outcome of the manual classification of removal methods within the context of RQ4. Schema:
  - `cve` - CVE ID
  - `how_short` - The removal category
  - `how_long` - The full description of the removal

## Replication steps

Here we explain each steps that involves running the scripts.

Requirements:

- `git`
- `python3`
- `pip3`

Before starting it is suggested installing the required Python packages: `pip3 install -r requirements.txt`.

Setup Used: *Intel Core i5-8250U (4+4 CPUs up to 3.4 GHz), 8 GB RAM, 20 GB Swap, OS: Manjaro Linux 20.1.12 (Mikah), Kernel: Linux 5.4.72-1-MANJARO, x86-64 bit*

You may need to set your `/tmp` size to at least 8GB: `mount -o remount,size=8G /tmp/` when running the scripts involving the cloning of repositories.

### Vulnerability Data Extraction

The script `extract_cve.py` takes `nvd_raw.json` and returns `cves.json`. It also prints on `stdout` some metrics related to the extracted CVEs, such as:

- Number of considered CVEs out the total
- Number of CVEs with more than one fixing commit

The execution may require **several minutes**.

Note that `cwe` data are mined with separate API calls, so this script requires an Internet connection.

### Enrich Repsitories: Fix and Inducing Commits Data and Releases

The script `enrich_repos.py` takes `cves.json` and returns a pretty printed `repos_enriched.json`.

The execution may require **several hours** (especially because of large repositories such as **Linux**, with over 900 vulnerabilities) and requires and an Internet connection (for cloning the repositories from GitHub).

It is suggested to run the script without considering Linux repository first and then, separately, run it again on Linux only.

This script ignores the following files:

- All files belonging to the following extensions: `{'.txt', '.md', '.man', '.lang', '.loc', '.tex', '.texi', '.rst', '.gif', '.png', '.jpg', '.jpeg', '.svg', '.ico', '.css', '.scss', '.less', '.gradle', '.ini', '.zip', '.pdf'}`
- All files matching the following (Python) regex: `r"^(install|changelog(s)?|change(s)?|author(s)?|news|readme|todo|about(s)?|credit(s)?|license|release(s)?|release(s)?|release(_|-)note(s)?|version(s)?|makefile|pom|\.git.*|\.travis|\.classpath|\.project)$"`
- All test files

### Extracting Information from Projects

The script `projects_info.py` takes `repos_enriched.json` and returns `projects_info.csv`.

The execution may require **several hours** (especially because of large repositories such as **Linux**) and requires and an Internet connection (for cloning the repositories from GitHub).

### Top-10 CWE

The script `top_10_cwe.py` takes `repos_enriched.json` and returns `top10cwe.csv`.

### SZZ Validation

The script `szz_validation.py` takes `szz_validation.csv` and prints out the outcome and agreement measures.

### Data Preparation

The script `data_preparation.py` takes `repos_enriched.json` and `removal_methods.csv` to produce the input datasets (`rqX_input.csv`) needed for the analyses of the four RQs and the discarded data from RQ2 and RQ3 (`rq2_discarded.csv` and `rq3_discarded.csv`).

### Analysis Scripts

The following scripts replicate the analyses made for the four RQs:

- `rq1.py`
- `rq2.py`
- `rq3.py`
- `rq4.py`

# Categorization Keywords (RQ2)
- New Feature: `{new, feature, add, creat, introduc, implement}`
- Bug Fix: `{fix, repair, error, bug, issue, exception}`
- Enhancement: `{updat, modif, upgrad, export, remov, integrat, support, enhancement, replac, includ, expos, generat, migrat}`
- Refactoring: `{renam, reorganiz, refactor, clean, polish, mov, extract, reorder, re-order, merg}`

# Removal Methods Taxonomy (RQ4)

## User-related
- **Sanitize External Input**: Adjust the content of externally supplied data before using it, e.g., escaping/encoding special characters, remove decimals, relying on parameterization.
- **Change User Permissions**: Change the assignment of functionalities to the different users/actors.
- **Hide Sensitive Information**: Do not allow passwords/tokens/keys and similar to be written in source code or be given to user.
- **Ask User Confirmation**: Add a confirm dialog or an extra input to avoid issuing operations unintentionally.
- **Improve Session Management**: Invalidate a session on logout or resuse a pre-existing session only when needed.
- **Limit Attempts**: Limit the attempts to login-like functionalities.

## Memory Management
- **Prevent Access Over Bounds**: Check if a pointer's offset does not go beyond the buffer limit or check if the signed integer buffer's length does not overflow, e.g., when used in fread().
- **Check Before Dereferencing**: Check if a pointer is not NULL before dereferencing it.
- **Change Buffer Size**: Increase/decrease the size of a dynamically allocated buffer (e.g., malloc()-like functions) or statically allocated variable.
- **Check Input Size**: Check the size (bytes) of externally supplied data in advance.
- **Remove Type Confusion**: Remove cases where a resource (e.g., a buffer) is accessed in an improper way (e.g., with unions or wrong pointer types).
- **Set Pointer To Null After Free**: Set a pointer to NULL after its use in a free().
- **Remove Invalid Free**: Remove free() calls on non-dynamically allocated buffers.

## Implementation
- **Handle Error Cases**: Handle exceptions/signals/error return values previously not considered. This comprises loop exit conditions and integer under/overflows, too.
- **Employ New Algorithm**: Employ a brand new algorithm for checking security-related aspects (either implemented from scratch or resusing existing solutions).
- **Fix Initialization**: Put objects/structs in a proper initial state, e.g., when creating an object starting from another (clone).
- **Remove Race Conditions**: Fix concurrency issues.
- **Remove Discrepancies Among Inputs**: Hide different behaviours (e.g., outputs, time) of an algorithm under different inputs (i.e.,treat malformed inputs similarly to valid ones).
- **Remove Vulnerable Code**: Remove the vulnerable feature/file code completely.
- **Avoid Deserialization of Untrusted And Harmful Data**: Deserialize only the unharmful part of untrusted data or prevent it at all.
- **Improve Resource Management**: Set a limit to the number of allocated resources (e.g., TCP sack holes, file descriptors, etc.);avoid opening them when not strictly needed or close them when not needed anymore.

## Networking
- **Implement Synchronizer Token Pattern**: Implement STP technique.
- **Improve Referer Header Check**: Ensure that the `referer' header fully matches with the website domain.
- **Improve Certificate Verification**: Check the certificate validity (its digital signature and origin).
- **Redirect After Unsafe HTTP Method**: Use 303 redirection to a different page after POST, PUT or DELETE requests (e.g., logins and payments).
- **Remove Untrusted Hosts**: Remove hosts that were considered as trusted.

## Configuration
- **Improve Security Configuration**: Modify security-related configuration (e.g., framework settings, configuration files, dependencies).
