import csv
import json
import os
import shutil

from git import GitCommandError, Repo
from pydriller import GitRepository

in_filepath = "../data/repos_enriched.json"
out_filepath = "../data/projects_info.csv"
tmp = "/tmp/"


def clone_repo(url, name):
    repo_filepath = tmp + name
    if not os.path.exists(repo_filepath):
        parts = url.split('://', 1)
        # This automatically skips private repositories
        repo_url_no_credentials = parts[0] + "://:@" + parts[1]
        try:
            print("Cloning from remote...")
            Repo.clone_from(repo_url_no_credentials, repo_filepath)
            print("Cloning done!")
        except GitCommandError as ger:
            raise ger
    else:
        print("Repository already cloned")
    git_repo = GitRepository(repo_filepath)
    git_repo.reset()
    return git_repo


enriched_repos = []
with open(in_filepath, "r") as in_file:
    enriched_repos = json.load(in_file)

total_iter = len(enriched_repos)
current_iter = 0
for er in enriched_repos:
    url = er["repo"]
    project = os.path.basename(os.path.normpath(url))
    project_info = {
        "project": project,
        "url": url,
    }

    current_iter += 1

    # TODO REMOVE DEBUG
    #if current_iter < 116:
    #    continue

    print("\n({}/{}) Working on {}".format(current_iter,
          total_iter, url))
    try:
        git_repo = clone_repo(url, project)
    except GitCommandError:
        print("Clone failed, skipping repository...")
        continue

    num_commits = int(git_repo.repo.git.rev_list(
        "--count", "HEAD", "--no-merges", "--before='2020-11-01'"))
    if num_commits > 0:
        project_info["commits"] = num_commits
    else:
        project_info["commits"] = 0

    authors = git_repo.repo.git.shortlog(
        "-s", "-n", "--no-merges").splitlines()
    num_contributors = len(authors)
    if num_contributors > 0:
        project_info["contributors"] = num_contributors
    else:
        project_info["contributors"] = 0
    
    project_info["cves"] = len(er["cves"])

    # Load current content
    projects_info = []
    with open(out_filepath, "r") as in_file:
        content = csv.DictReader(in_file, skipinitialspace=True)
        projects_info.extend([{k: v for k, v in row.items()} for row in content])
    projects_info.append(project_info)

    # Update CSV
    with open(out_filepath, 'w') as out_file:
        writer = csv.DictWriter(out_file, fieldnames=projects_info[0].keys())
        writer.writeheader()
        writer.writerows(projects_info)
    shutil.rmtree(tmp + project)
