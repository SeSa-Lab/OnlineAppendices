import pandas as pd

input_file_path = "../data/rq1_input.csv"
top_10_cwe = "../data/top10cwe.csv"

df_inducings = pd.read_csv(input_file_path, delimiter=",")

# Simple Profiling
num_inducings = df_inducings.groupby(["repo", "hash"]).size().count()
num_repos = df_inducings["repo"].nunique()
num_cwes = df_inducings["cwe"].nunique()
num_files = df_inducings.groupby(["repo", "file"]).size().count()
print("Inducing Commits: {}".format(num_inducings))
print("Repos w/ Inducing Commits: {}".format(num_repos))
print("CWEs: {}".format(num_cwes))
print("Files (touched by inducing commits) : {}".format(num_files))

# Group by CVE and count
cve_groups = df_inducings.groupby("cve", sort=False)
num_cves = len(cve_groups)
print("CVEs w/ Inducing Commits: {}".format(num_cves))
print()

# Descriptive statistics of number of inducing commits per CVE
number_inducings_per_cve = cve_groups["hash"].nunique()
print("Summary of Number of Inducing Commits per CVE")
print(round(number_inducings_per_cve.describe(), 2))
print()

# CVEs with > 1 inducing commit
cve_with_many_inducings_count = (number_inducings_per_cve > 1).sum()
cve_with_many_inducings_perc = cve_with_many_inducings_count / num_cves * 100
print("Number of CVEs with > 1 Inducing Commit: {}/{} ({}%)".format(cve_with_many_inducings_count, num_cves, round(cve_with_many_inducings_perc, 2)))
print()

# CVEs with the maximum number of inducing commits and its related data
number_inducings_per_cve_idxmax = number_inducings_per_cve.idxmax()
number_inducings_per_cve_max = number_inducings_per_cve.max()
cve_max_inducings = cve_groups.get_group(number_inducings_per_cve_idxmax)
cve_group_max_inducings_files_count = cve_max_inducings["file"].nunique()
cve_group_max_inducings_added_lines = cve_max_inducings["added_lines"].sum()
cve_group_max_inducings_removed_lines = cve_max_inducings["removed_lines"].sum()
print("{} has Highest Number of Inducing Commits ({}): all of them touched a total of {} Files, by Adding {} and Removing {} Lines".format(number_inducings_per_cve_idxmax, number_inducings_per_cve_max, cve_group_max_inducings_files_count, cve_group_max_inducings_added_lines, cve_group_max_inducings_removed_lines))
print()

# Descriptive statistics of number of touched files per Inducing Commit
print("Summary of Touched Files per Inducing Commit")
number_files_per_inducing = df_inducings.groupby(["repo", "hash"], sort=False)["file"]
number_files_per_inducing_count = number_files_per_inducing.nunique()
print(round(number_files_per_inducing_count.describe(), 2))
print()

# Inducing Commits > 10 different files
inducings_more_ten_files_count = number_files_per_inducing_count[number_files_per_inducing_count > 10].count()
inducings_more_ten_files_perc = inducings_more_ten_files_count / num_inducings * 100
print("Inducing Commits that Changed More than 10 Different Files: {}/{} ({}%)".format(inducings_more_ten_files_count, num_inducings, round(inducings_more_ten_files_perc, 2)))
print()

# For each CVE and for each affected file get its first inducing commit (there may be repeated commits). Then compute the mean of commits_since_file_creation among all rows. Finally, add to each commit the number of inducing commits of each related CVE. Repeat the same procedure for the turning point.
df_first_inducings = df_inducings[cve_groups["date"].transform(min) == df_inducings["date"]]
first_inducings_since_creation = df_first_inducings["commits_since_file_creation"]
df_merged = pd.merge(df_first_inducings, number_inducings_per_cve, on="cve")
df_merged.rename({"hash_y": "number_inducings_of_cve"}, axis=1, inplace=True)
turnings_since_creation = df_merged["commits_since_file_creation"] + df_merged["number_inducings_of_cve"] - 1
print("Summary of Commits Since File Creation of First Inducing Commits of each CVE")
print(round(first_inducings_since_creation.describe(), 2))
print()
print("Summary of Commits Since File Creation of Turning Points of each CVE")
print(round(turnings_since_creation.describe(), 2))
print()

# Files that were created in an IC (i.e., commits_since_file_creation == 1); Files that were created in an IC that is the only one for its CVE
files_created_inducing = df_inducings.loc[df_inducings["commits_since_file_creation"] == 1, ["repo", "file"]].drop_duplicates(ignore_index=True)
files_cves_one_inducing = cve_groups.filter(lambda x: len(x) == 1)[["repo", "file"]].drop_duplicates(ignore_index=True)
files_cves_one_inducing_created = pd.merge(files_created_inducing, files_cves_one_inducing, on=["repo", "file"])
files_created_inducing_count = len(files_created_inducing)
files_cves_one_inducing_created_count = len(files_cves_one_inducing_created)
print("Files Created within an Inducing Commit: {}/{} ({}%)".format(files_created_inducing_count, num_files, round(files_created_inducing_count / num_files * 100, 2)))
print("Files that were Created in an Inducing Commits that is the Only One for its CVE : {}/{} ({}%)".format(files_cves_one_inducing_created_count, files_created_inducing_count, round(files_cves_one_inducing_created_count / files_created_inducing_count * 100, 2)))

# Files that required > 500 commits to reach their very first IC
files_first_inducing = df_inducings[df_inducings.groupby(["repo", "file"], sort=False)["commits_since_file_creation"].transform(min) == df_inducings["commits_since_file_creation"]]
files_over_500 = files_first_inducing.loc[files_first_inducing["commits_since_file_creation"] > 500, ["repo", "file", "commits_since_file_creation"]].sort_values(by="commits_since_file_creation", ascending=False, ignore_index=True)
files_over_500_count = len(files_over_500)
print("Files that Started Becaming Vulnerable after over 500 commits: {}/{} ({}%)".format(files_over_500_count, num_files, round(files_over_500_count / num_files * 100, 2)))
print()

# Relevant statistics on the top-10 CWE
top_10_cwe = pd.read_csv(top_10_cwe)["cwe"].to_list()
df_top_10 = pd.DataFrame()
for cwe in top_10_cwe:
    df_cwe = df_inducings[df_inducings["cwe"] == cwe]
    df_top_10 = df_top_10.append(df_cwe)
top_10_cwe_groups = df_top_10.groupby("cwe", sort=False)
print("Summary of Top-10 CWE")
for name, group_df in top_10_cwe_groups:
    group_df_inducings = group_df.groupby("cve", sort=False)["hash"].nunique()
    print()
    print(name)
    print(round(group_df_inducings.describe(), 2))
